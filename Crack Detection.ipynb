{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c92cf1a-7772-4014-b3fd-e939b8b823fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6039176d-b801-4d8a-bc05-bd7d9ab2acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Image dimensions\n",
    "num_px = 64\n",
    "\n",
    "# Function to extract features and labels for training\n",
    "def extract_features_and_labels_from_folders(base_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder_name in enumerate(['negative', 'positive']):  # 0 = negative, 1 = positive\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Directory does not exist: {folder_path}\")\n",
    "            continue\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "            img = img / 255.0  # Normalize\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5704b087-5e9a-47b3-9afa-ef0dd84f2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features for testing\n",
    "def extract_features(directory):\n",
    "    X = []\n",
    "    filenames = []\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "        img = img / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        filenames.append(img_name)\n",
    "    return np.array(X), filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0bc53d1-83b1-4d5e-9751-2099bb93a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_dir = './training'\n",
    "train_X, train_Y = extract_features_and_labels_from_folders(train_dir)\n",
    "\n",
    "# One-hot encode labels\n",
    "train_Y_one_hot = to_categorical(train_Y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8fbc291-5ab9-4216-bbba-dfc7db90a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 3)),  # Input layer with shape\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2cf1282-a081-4dba-95d4-c30c24198e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 47ms/step - accuracy: 0.9407 - loss: 0.1369\n",
      "Epoch 2/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - accuracy: 0.9899 - loss: 0.0306\n",
      "Epoch 3/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - accuracy: 0.9937 - loss: 0.0211\n",
      "Epoch 4/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - accuracy: 0.9932 - loss: 0.0227\n",
      "Epoch 5/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 332ms/step - accuracy: 0.9958 - loss: 0.0141\n",
      "Epoch 6/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - accuracy: 0.9966 - loss: 0.0122\n",
      "Epoch 7/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - accuracy: 0.9963 - loss: 0.0118\n",
      "Epoch 8/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - accuracy: 0.9966 - loss: 0.0123\n",
      "Epoch 9/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9974 - loss: 0.0086\n",
      "Epoch 10/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9973 - loss: 0.0097\n",
      "Epoch 11/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 60ms/step - accuracy: 0.9981 - loss: 0.0062\n",
      "Epoch 12/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9977 - loss: 0.0068\n",
      "Epoch 13/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0045\n",
      "Epoch 14/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - accuracy: 0.9989 - loss: 0.0048\n",
      "Epoch 15/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - accuracy: 0.9976 - loss: 0.0082\n",
      "Epoch 16/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 78ms/step - accuracy: 0.9987 - loss: 0.0046\n",
      "Epoch 17/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 82ms/step - accuracy: 0.9991 - loss: 0.0033\n",
      "Epoch 18/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 62ms/step - accuracy: 0.9990 - loss: 0.0038\n",
      "Epoch 19/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 58ms/step - accuracy: 0.9993 - loss: 0.0029\n",
      "Epoch 20/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - accuracy: 0.9987 - loss: 0.0048\n",
      "Total Training Time: 1473.45019603 seconds\n",
      "Final Training Accuracy: 99.86607432%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a21566ba-c7e5-4df2-abc7-4c940dfc2026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: ./test/.DS_Store\n",
      "Predicting on test data...\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step\n",
      "Results saved to 'test_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load testing data\n",
    "test_dir = './test'\n",
    "test_X, test_filenames = extract_features(test_dir)\n",
    "\n",
    "# Predict on test data\n",
    "print(\"Predicting on test data...\")\n",
    "predicted_classes = np.argmax(model.predict(test_X), axis=1)\n",
    "\n",
    "# Map predictions to class names\n",
    "class_map = {0: 'Negative', 1: 'Positive'}\n",
    "predicted_labels = [class_map[pred] for pred in predicted_classes]\n",
    "\n",
    "# Save results to CSV\n",
    "output = pd.DataFrame({'Filename': test_filenames, 'Class': predicted_labels})\n",
    "output.to_csv('test_results.csv', index=False)\n",
    "print(\"Results saved to 'test_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af54f8f3-9fe7-4219-b30e-3abb6f82b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - accuracy: 0.9100 - loss: 0.1941\n",
      "Epoch 2/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - accuracy: 0.9872 - loss: 0.0459\n",
      "Epoch 3/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - accuracy: 0.9893 - loss: 0.0349\n",
      "Epoch 4/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - accuracy: 0.9934 - loss: 0.0237\n",
      "Epoch 5/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9947 - loss: 0.0168\n",
      "Epoch 6/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - accuracy: 0.9956 - loss: 0.0145\n",
      "Epoch 7/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - accuracy: 0.9959 - loss: 0.0133\n",
      "Epoch 8/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 57ms/step - accuracy: 0.9974 - loss: 0.0099\n",
      "Epoch 9/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - accuracy: 0.9978 - loss: 0.0080\n",
      "Epoch 10/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - accuracy: 0.9975 - loss: 0.0067\n",
      "Total Training Time: 560.16397405 seconds\n",
      "Final Training Accuracy: 99.75706339%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e98baae2-2296-489f-9a81-21df5fa2201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 96ms/step - accuracy: 0.8935 - loss: 0.2071\n",
      "Epoch 2/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.9865 - loss: 0.0456\n",
      "Epoch 3/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.9907 - loss: 0.0307\n",
      "Epoch 4/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.9927 - loss: 0.0232\n",
      "Epoch 5/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.9946 - loss: 0.0163\n",
      "Epoch 6/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.9971 - loss: 0.0088\n",
      "Epoch 7/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 104ms/step - accuracy: 0.9970 - loss: 0.0100\n",
      "Epoch 8/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 105ms/step - accuracy: 0.9977 - loss: 0.0069\n",
      "Epoch 9/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9981 - loss: 0.0062\n",
      "Epoch 10/10\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 107ms/step - accuracy: 0.9970 - loss: 0.0103\n",
      "Total Training Time: 521.71095586 seconds\n",
      "Final Training Accuracy: 99.72591400%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "982b7f6f-2489-4340-b931-1840c2964c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 207ms/step - accuracy: 0.9291 - loss: 0.1874\n",
      "Epoch 2/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 204ms/step - accuracy: 0.9905 - loss: 0.0287\n",
      "Epoch 3/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 204ms/step - accuracy: 0.9929 - loss: 0.0257\n",
      "Epoch 4/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 204ms/step - accuracy: 0.9918 - loss: 0.0261\n",
      "Epoch 5/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 207ms/step - accuracy: 0.9944 - loss: 0.0167\n",
      "Epoch 6/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 204ms/step - accuracy: 0.9957 - loss: 0.0147\n",
      "Epoch 7/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 204ms/step - accuracy: 0.9972 - loss: 0.0091\n",
      "Epoch 8/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 219ms/step - accuracy: 0.9967 - loss: 0.0119\n",
      "Epoch 9/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 211ms/step - accuracy: 0.9981 - loss: 0.0084\n",
      "Epoch 10/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 204ms/step - accuracy: 0.9970 - loss: 0.0097\n",
      "Total Training Time: 2183.82775497 seconds\n",
      "Final Training Accuracy: 99.77886677%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Image dimensions\n",
    "num_px = 128\n",
    "\n",
    "# Function to extract features and labels for training\n",
    "def extract_features_and_labels_from_folders(base_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder_name in enumerate(['negative', 'positive']):  # 0 = negative, 1 = positive\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Directory does not exist: {folder_path}\")\n",
    "            continue\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "            img = img / 255.0  # Normalize\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to extract features for testing\n",
    "def extract_features(directory):\n",
    "    X = []\n",
    "    filenames = []\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "        img = img / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        filenames.append(img_name)\n",
    "    return np.array(X), filenames\n",
    "# Load training data\n",
    "train_dir = './training'\n",
    "train_X, train_Y = extract_features_and_labels_from_folders(train_dir)\n",
    "\n",
    "# One-hot encode labels\n",
    "train_Y_one_hot = to_categorical(train_Y, 2)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 128, 3)),  # Input layer with shape\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Binary classification\n",
    "])\n",
    "\n",
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "978d2a17-be9f-41de-9f5c-739324868e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 67ms/step - accuracy: 0.9210 - loss: 0.1737\n",
      "Epoch 2/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 71ms/step - accuracy: 0.9911 - loss: 0.0282\n",
      "Epoch 3/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.9947 - loss: 0.0183\n",
      "Epoch 4/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9963 - loss: 0.0133\n",
      "Epoch 5/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 71ms/step - accuracy: 0.9973 - loss: 0.0111\n",
      "Epoch 6/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - accuracy: 0.9969 - loss: 0.0107\n",
      "Epoch 7/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 71ms/step - accuracy: 0.9979 - loss: 0.0060\n",
      "Epoch 8/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 72ms/step - accuracy: 0.9977 - loss: 0.0079\n",
      "Epoch 9/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 72ms/step - accuracy: 0.9981 - loss: 0.0059\n",
      "Epoch 10/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9981 - loss: 0.0082\n",
      "Total Training Time: 725.86887193 seconds\n",
      "Final Training Accuracy: 99.82869625%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Image dimensions\n",
    "num_px = 64\n",
    "\n",
    "# Function to extract features and labels for training\n",
    "def extract_features_and_labels_from_folders(base_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder_name in enumerate(['negative', 'positive']):  # 0 = negative, 1 = positive\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Directory does not exist: {folder_path}\")\n",
    "            continue\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "            img = img / 255.0  # Normalize\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to extract features for testing\n",
    "def extract_features(directory):\n",
    "    X = []\n",
    "    filenames = []\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "        img = img / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        filenames.append(img_name)\n",
    "    return np.array(X), filenames\n",
    "# Load training data\n",
    "train_dir = './training'\n",
    "train_X, train_Y = extract_features_and_labels_from_folders(train_dir)\n",
    "\n",
    "# One-hot encode labels\n",
    "train_Y_one_hot = to_categorical(train_Y, 2)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 3)),  # Input layer with shape\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Binary classification\n",
    "])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61dce6f7-0fd4-42c5-8eb0-b5684dc70ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.8803 - loss: 0.2706\n",
      "Epoch 2/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - accuracy: 0.9801 - loss: 0.0695\n",
      "Epoch 3/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 43ms/step - accuracy: 0.9885 - loss: 0.0446\n",
      "Epoch 4/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - accuracy: 0.9892 - loss: 0.0362\n",
      "Epoch 5/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - accuracy: 0.9887 - loss: 0.0363\n",
      "Epoch 6/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9926 - loss: 0.0232\n",
      "Epoch 7/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9930 - loss: 0.0216\n",
      "Epoch 8/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9931 - loss: 0.0202\n",
      "Epoch 9/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.9955 - loss: 0.0142\n",
      "Epoch 10/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9956 - loss: 0.0135\n",
      "Total Training Time: 425.95752811 seconds\n",
      "Final Training Accuracy: 99.54527020%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Image dimensions\n",
    "num_px = 64\n",
    "\n",
    "# Function to extract features and labels for training\n",
    "def extract_features_and_labels_from_folders(base_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder_name in enumerate(['negative', 'positive']):  # 0 = negative, 1 = positive\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Directory does not exist: {folder_path}\")\n",
    "            continue\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "            img = img / 255.0  # Normalize\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to extract features for testing\n",
    "def extract_features(directory):\n",
    "    X = []\n",
    "    filenames = []\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "        img = img / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        filenames.append(img_name)\n",
    "    return np.array(X), filenames\n",
    "# Load training data\n",
    "train_dir = './training'\n",
    "train_X, train_Y = extract_features_and_labels_from_folders(train_dir)\n",
    "\n",
    "# One-hot encode labels\n",
    "train_Y_one_hot = to_categorical(train_Y, 2)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 3)),  # Input layer with shape\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Binary classification\n",
    "])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e8b9382-11b7-48b6-a5ae-26d26d610b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - accuracy: 0.9000 - loss: 0.2094\n",
      "Epoch 2/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - accuracy: 0.9843 - loss: 0.0494\n",
      "Epoch 3/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - accuracy: 0.9918 - loss: 0.0272\n",
      "Epoch 4/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - accuracy: 0.9945 - loss: 0.0179\n",
      "Epoch 5/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - accuracy: 0.9955 - loss: 0.0132\n",
      "Epoch 6/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - accuracy: 0.9963 - loss: 0.0114\n",
      "Epoch 7/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - accuracy: 0.9963 - loss: 0.0105\n",
      "Epoch 8/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - accuracy: 0.9957 - loss: 0.0127\n",
      "Epoch 9/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - accuracy: 0.9980 - loss: 0.0067\n",
      "Epoch 10/10\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - accuracy: 0.9984 - loss: 0.0059\n",
      "Total Training Time: 553.39954591 seconds\n",
      "Final Training Accuracy: 99.83804226%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Image dimensions\n",
    "num_px = 64\n",
    "\n",
    "# Function to extract features and labels for training\n",
    "def extract_features_and_labels_from_folders(base_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder_name in enumerate(['negative', 'positive']):  # 0 = negative, 1 = positive\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Directory does not exist: {folder_path}\")\n",
    "            continue\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "            img = img / 255.0  # Normalize\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to extract features for testing\n",
    "def extract_features(directory):\n",
    "    X = []\n",
    "    filenames = []\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (num_px, num_px))  # Resize to 64x64\n",
    "        img = img / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        filenames.append(img_name)\n",
    "    return np.array(X), filenames\n",
    "# Load training data\n",
    "train_dir = './training'\n",
    "train_X, train_Y = extract_features_and_labels_from_folders(train_dir)\n",
    "\n",
    "# One-hot encode labels\n",
    "train_Y_one_hot = to_categorical(train_Y, 2)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 3)),  # Input layer with shape\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Binary classification\n",
    "])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y_one_hot,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get the final accuracy from the training history\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Training Time: {training_time:.8f} seconds\")\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.8%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faeb50-717e-4834-9496-1c5c57a05dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
